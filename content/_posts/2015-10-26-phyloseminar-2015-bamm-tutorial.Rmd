---
author: brianomeara_ra6153
comments: false
date: 2015-10-26 13:32:36+00:00
layout: post
link: http://www.brianomeara.info/2015/10/26/phyloseminar-2015-bamm-tutorial/
slug: phyloseminar-2015-bamm-tutorial
title: 'Phyloseminar 2015: BAMM tutorial'
wordpress_id: 383
categories:
- Phyloseminar
- Teaching
---

[BAMM Tutorial Phyloseminar 2015.pdf](http://brianomeara.info/wordpress_beta/wp-content/uploads/2015/10/BAMM-Tutorial-Phyloseminar-2015.pdf)





# BAMM Tutorial Phyloseminar 2015




#### _[Orlando Schwery](https://sites.google.com/site/orlandoschwery/)_




#### _2015-10-25_







This tutorial largely follows the tutorials by Dan Rabosky on [his website](www.BAMM-project.org).







## Installation




BAMM consists of two components, the program that runs the actual analysis is in C++ (to be faster), while the analysis of the outputs happens in R.







### BAMM




Easiest might be to install it from the executables (both for Win and OS X), although from source and using homebrew is also possible.






  1. Go to the [Download-Page](http://bamm-project.org/download.html)


  2. download the appropriate BAMM version for your platform


  3. download the zipped example files


  4. unpack everything, in case of OS X, move to the appropriate directory in the command line and type



    
    <code>tar -xzf bamm-2.3.0-MacOSX.tar.gz</code>



  5. move the files and folders to the directory you want











### BAMMtools




For this one, simply open R and type



    
    <code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">'BAMMtools'</span>)</code>




If it is installed, load the package using



    
    <code class="sourceCode r"><span class="kw">library</span>(BAMMtools)</code>













## Run BAMM




In order to run BAMM, we need nothing more than a **tree** and a **controlfile**. We will use the whale examples in this tutorial. To run your own analysis, it is a good idea to simply modify the example controlfile or use the [template controlfile](http://bamm-project.org/_downloads/template_diversification.txt).




Let’s start the whale analysis and then look at the controlfile.







### Run the Whales




It is easiest to use BAMM when all files are in the same directory where BAMM is, so:






  1. move the whale tree and the controlfile in the same folder as BAMM


  2. to get a result that is looking a bit more realistic, we open the ‘divcontrol’ file and change `numberOfGenerations` from 10k to 1Mio


  3. change the directory of your command line to that folder


  4. start the analysis by typing:



    
    <code class="sourceCode r">./bamm -c divcontrol.txt   <span class="co"># on windows you can omit the './'</span></code>






  5. wait for the MCMC to start running


  6. the output files will be




  * chain_swap.txt


  * event_data.txt


  * mcmc_out.txt


  * prior_probs.txt


  * run_info.txt




The main data we want to look at later is in the **event_data** file, and we look at the file **mcmc_out** to assess convergence. You might want to keep the **run_info** file with your other files in order to know what settings you used for a specific analysis.










### A look at the controlfile




Go to the examples folder and find the ‘whales’ controlfile and tree in the ‘diversification’ subfolder. Open the controlfile ‘divcontrol.txt’. The file is pretty well annotated and most points should be fairly self-explanatory, we will quickly discuss some of them though.




Sections:






  * General Setup and Data Input


  * Priors


  * MCMC Simulation Settings & Output Options


  * Operators: MCMC Scaling Operators


  * Operators: MCMC Move Frequencies


  * Initial Parameter Values


  * Metropolis Coupled MCMC


  * Numerical and Other Parameters




Most values are preset in a way that will work out well, and most users work along the policy to not touch anything if you don’t know what it does, but a few parameters are worth looking at (the bold ones you definitely have to modify for your own analysis, or at least consider it…):






  * modeltype


  * **treefile**


  * useGlobalSamplingProbability


  * **globalSamplingFraction**


  * sampleProbsFilename



  * **all the priors…**



  * **numberOfGenerations**


  * **mcmcWriteFreq**


  * **eventDataWriteFreq**


  * **printFreq**


  * **acceptanceRateFreq**



  * scaling operators…



  * move frequencies…



  * **initial values…**



  * numberOfChains


  * deltaT


  * swapPeriod



  * minCladeSizeForShift


  * segLength





More in-depth treatment of how to fine-tune the analysis and how to use advanced features can be found [here](http://bamm-project.org/advanced.html)













## Analyse outputs with BAMMtools




Now we want to dig into the outputs of the analysis, which we do in R. There are a number of different options regarding what we can do and should do, and we try to look at the most important ones here.







### Convergence




Just like for any MCMC analyses, _e.g._ when we date a tree with BEAST, we want to know if we ran the analysis long enough to reach convergence. To do this for BAMM, we look at the file **mcmc_out** in R:



    
    <code class="sourceCode r">mcmc <-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">"/Users/orlandoschwery/Documents/UT/Courses/Fall 15/Phyloseminar/BAMMtutorial/mcmc_out.txt"</span>, <span class="dt">header=</span>T)  <span class="co"># load file</span>
    <span class="kw">dim</span>(mcmc)  <span class="co"># check dimensions</span>
    <span class="kw">head</span>(mcmc)  <span class="co"># check head</span></code>




Now we can look at the trace plot of the log likelihood per generation (and if we want at the numbers of shifts per generation)



    
    <code class="sourceCode r"><span class="kw">plot</span>(mcmc$logLik ~<span class="st"> </span>mcmc$generation)
    <span class="kw">plot</span>(mcmc$N_shifts ~<span class="st"> </span>mcmc$generation)</code>




Now we want to discard a reasonable portion as burnin, _e.g._ 10%…



    
    <code class="sourceCode r">burnstart <-<span class="st"> </span><span class="kw">floor</span>(<span class="fl">0.1</span> *<span class="st"> </span><span class="kw">nrow</span>(mcmc))
    mcmcpost <-<span class="st"> </span>mcmc[burnstart:<span class="kw">nrow</span>(mcmc), ]</code>




… and calculate the effective sample size, which should exceed 200 if our analyses ran long enough (although different people might argue for different minimal values here).



    
    <code class="sourceCode r"><span class="kw">library</span>(coda)
    <span class="kw">effectiveSize</span>(mcmcpost$logLik)  <span class="co"># calculates autocorrelation function</span>
    <span class="kw">effectiveSize</span>(mcmcpost$N_shift)  <span class="co"># effective size on N_shifts</span>
    ## do this on pre-burnin MCMC
    <span class="kw">effectiveSize</span>(mcmc$logLik)
    <span class="kw">effectiveSize</span>(mcmc$N_shift)</code>










### Rate Shifts




Now for the thing we are most interested in: the rate shifts. We load the package BAMMtools, the tree we used and the event_data file, for which we specify the same burnin we decided on before:



    
    <code class="sourceCode r"><span class="kw">library</span>(BAMMtools)
    tree <-<span class="st"> </span><span class="kw">read.tree</span>(<span class="st">"/Users/orlandoschwery/Documents/UT/Courses/Fall 15/Phyloseminar/BAMMtutorial/whaletree.tre"</span>)
    ed <-<span class="st"> </span><span class="kw">getEventData</span>(tree, <span class="st">"/Users/orlandoschwery/Documents/UT/Courses/Fall 15/Phyloseminar/BAMMtutorial/event_data.txt"</span>, <span class="dt">burnin=</span><span class="fl">0.1</span>)</code>




It is possible to subset the event data file, if the size is too big for R to handle.







#### Phylorates Plots




Now we can just look at the mean rates inferred:



    
    <code class="sourceCode r"><span class="kw">plot.bammdata</span>(ed, <span class="dt">legend=</span>T, <span class="dt">spex=</span><span class="st">'netdiv'</span>)</code>




We can also look at speciation or extinction rates separately:



    
    <code class="sourceCode r"><span class="kw">plot.bammdata</span>(ed, <span class="dt">legend=</span>T, <span class="dt">spex=</span><span class="st">'s'</span>)
    <span class="kw">plot.bammdata</span>(ed, <span class="dt">legend=</span>T, <span class="dt">spex=</span><span class="st">'e'</span>)</code>




We can get a first idea on what number of shifts were most commonly found using summary (this just tells us how many samples contain a certain number of shifts, but not WHERE those shifts are):



    
    <code class="sourceCode r"><span class="kw">summary</span>(ed)</code>










#### Bayes Factors for Shift Models




To get a more robust idea of how certain shift models are performing compared to each other, we can calculate Bayes Factors:



    
    <code class="sourceCode r">postfile <-<span class="st"> </span>mcmc  <span class="co"># since we already loaded this</span>
    priorfile <-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">"/Users/orlandoschwery/Documents/UT/Courses/Fall 15/Phyloseminar/BAMMtutorial/prior_probs.txt"</span>, <span class="dt">header=</span>T)
    bfmat <-<span class="st"> </span><span class="kw">computeBayesFactors</span>(postfile, priorfile, <span class="dt">burnin=</span><span class="fl">0.1</span>)</code>




The resulting table shows how models with certain numbers of shifts compare to a specific other one, BFs of >20 indicate good support that a model is better than the one it is compared to, BFs of >50 indicate very strong support.










#### Credible Shift Sets




What our data actually looks like now, are different samples of shift regimes, all of which are sampled at a certain frequency. We can access each of them, and it is a good idea to visualize the most frequent ones:



    
    <code class="sourceCode r">pset <-<span class="st"> </span><span class="kw">getBranchShiftPriors</span>(tree, priorfile)
    cset <-<span class="st"> </span><span class="kw">credibleShiftSet</span>(ed, pset, <span class="dt">BFcriterion=</span><span class="dv">3</span>)
    <span class="kw">plot.credibleshiftset</span>(cset, <span class="dt">lwd=</span><span class="fl">2.5</span>)</code>










#### Best Shift Set




Based on the credible shift sets, we might conclude that the most commonly sampled configuration of shifts is the best one:



    
    <code class="sourceCode r">best <-<span class="st"> </span><span class="kw">getBestShiftConfiguration</span>(ed, <span class="dt">prior =</span> pset)
    <span class="kw">plot.bammdata</span>(best, <span class="dt">lwd =</span> <span class="dv">2</span>)
    <span class="kw">addBAMMshifts</span>(best, <span class="dt">cex=</span><span class="fl">2.5</span>)</code>










#### Maximum Shift Credibility




Alternatively, pick the shiftset that maximizes the marginal likelihood of a shift on a branch, a set of maximum shift credibility, similar to when we get a maximum clade credibility tree out of a set of trees:



    
    <code class="sourceCode r">msc.set <-<span class="st"> </span><span class="kw">maximumShiftCredibility</span>(ed, <span class="dt">maximize=</span><span class="st">'product'</span>)
    msc.config <-<span class="st"> </span><span class="kw">subsetEventData</span>(ed, <span class="dt">index =</span> msc.set$sampleindex)
    <span class="kw">plot.bammdata</span>(msc.config, <span class="dt">lwd=</span><span class="dv">2</span>)
    <span class="kw">addBAMMshifts</span>(msc.config, <span class="dt">cex =</span> <span class="dv">2</span>)</code>













### Macroevolutionary Cohort Analysis




When we have rate shifts to lower or higher rates, some sampled configurations might cancel each other out ( _i.e._ some say speedup for sisterclade A, some say slowdown for sisterclade B). We can catch this (and more) by looking at the cohort matrix:



    
    <code class="sourceCode r">cmat <-<span class="st"> </span><span class="kw">getCohortMatrix</span>(ed)
    <span class="kw">cohorts</span>(cmat, ed)</code>




Fin!









