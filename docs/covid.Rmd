---
author: Brian O'Meara
title: Local COVID data
---

Here are notes and links I personally find useful, all gathered in one place. Mostly, I kept looking at webcams to see whether people are practicing social distancing and decided to put them all in one page. I also gather data when nervous, so I also have plots of things like testing, activity, and cases over time so I can see the info directly myself (for example, <a href="https://covid.knoxcountytn.gov/case-count.html#covid_data">Knox County Health Department</a> plots cases per day with a trendline, but so far their trendline is only a straight line - I was curious if a more flexible fitting might be more informative). <b>I am not an epidemiologist</b>, so please do not draw any advice from this page (and I've been careful NOT to do projections or anything like that -- there is a lot that goes into modeling, see <a href="https://www.youtube.com/watch?v=Ewuo_2pzNNw">this video</a> by my colleague <a href="http://feffermanlab.org/">Nina Fefferman</a>, who unlike me is an expert in this, for more on models). This is just me poking around with the data to make myself feel better -- the raw code is <a href="https://github.com/bomeara/brianomearainfo/blob/master/docs/covid.Rmd">here</a> if you'd like to examine it yourself.

<hr />


* <a href="https://www.utk.edu/coronavirus/">UTK coronavirus information</a>. See especially the <a href="https://chancellor.utk.edu/re-imagining-fall-task-force/report/">current task force report</a>.
* <a href="https://covid.knoxcountytn.gov/case-count.html#covid_data">Knox County data</a>. This also includes info about Knox's reopening plan and the benchmarks they're using
* <a href="https://insideofknoxville.com/">Inside of Knoxville</a> has reporting out of every health board meeting and other local news.
* <i><a href="https://www.knoxnews.com/news/">Knoxville News Sentinel</a></i> is our remaining local paper (though some of its staff have been furloughed) and it covers covid in Knoxville and Knox County.
* <a href="https://covid19-projections.com/us-tn">Projections for Tennessee</a>
* <a href="https://covidactnow.org/us/tn?s=49762">Covid ActNow aggregate</a> of information, including contact tracing, infection rate, and more
* <a href="https://nextstrain.org/ncov">COVID-19 phylogeny</a>. Family tree of the COVID-19 viruses around the world. This can be used by experts to understand how the disease has spread and is continuing to spread, as well as possible evolution during its spread.
* <a href="https://projects.propublica.org/reopening-america/">ProPublica's tracker of state status</a>. Click on the play button below their map to see how rates are changing over time, and dig into info on your state.

<hr />

Here are some plots, created in R using data from https://covid19datahub.io (Guidotti, E., Ardia, D., (2020), "COVID-19 Data Hub", Working paper, doi: 10.13140/RG.2.2.11649.81763), as well as information from Google and the <a href="https://www.tn.gov/health/cedep/ncov/data/downloadable-datasets.html">state of Tennessee dataset page</a> and plotting and analysis using the `forecast`, `ggplot2`, `reshape2`, and `dplyr` packages. It also uses the <a href="https://github.com/mtna/rds-r">rds-r</a> package from https://www.richdataservices.com/. Plots created on `r Sys.time()`. I use `ggplot2`'s `geom_smooth()` function for the smoothed regression plots with its default formula, which uses loess smoothing for this many points. This is  not based on a model of disease spread or anything similarly sophisticated, just drawing a smooth curve to summarize noisy points (see <a href="https://www.itl.nist.gov/div898/handbook/pmd/section1/pmd144.htm">here</a> for more details).

```{r data, echo=FALSE, message=FALSE, warning=FALSE}
library(COVID19)
library(forecast)
library(ggplot2)
library(reshape2)
library(dplyr)
library(readxl)
library(stringr)
library(anytime)
# devtools::install_github("mtna/rds-r", build_vignettes = TRUE)
library(rds.r)
library(ggrepel)
library(ggpubr)


gmr <- "https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv"


us <- COVID19::covid19(country="US", level=3, gmr=gmr, verbose=FALSE)
tn <- subset(us, administrative_area_level_2=="Tennessee")
knox <- subset(us, administrative_area_level_3=="Knox" & administrative_area_level_2=="Tennessee")
knox$percentconfirmed <- 100*knox$confirmed/knox$population


tn_aggregate <- tn %>% group_by(date) %>% summarise(confirmed = sum(confirmed), population=sum(population))
tn_aggregate$percentconfirmed <- 100*tn_aggregate$confirmed/tn_aggregate$population

tn_diff <- data.frame(date=tn_aggregate$date[-1], daily_confirmed=diff(tn_aggregate$confirmed), daily_percent_confirmed=diff(tn_aggregate$percentconfirmed))


us_aggregate <- us %>% group_by(date) %>% summarise(confirmed = sum(confirmed), population=sum(population))
us_aggregate$percentconfirmed <- 100*us_aggregate$confirmed/us_aggregate$population

us_diff <- data.frame(date=us_aggregate$date[-1], daily_confirmed=diff(us_aggregate$confirmed), daily_percent_confirmed=diff(tn_aggregate$percentconfirmed))

knox_diff <- data.frame(
  date=knox$date[-1],
  daily_confirmed=diff(knox$confirmed),
  daily_tested=diff(knox$tests),
  daily_recovered=diff(knox$recovered),
  daily_workplace=diff(knox$workplaces_percent_change_from_baseline),
  daily_retail_recreation=diff(knox$retail_and_recreation_percent_change_from_baseline),
  daily_residential=diff(knox$residential_percent_change_from_baseline),
  daily_percent_confirmed = diff(knox$percentconfirmed)
)

#
#
# knox_diff_last_three_weeks <- tail(knox_diff,21)
# knox_diff_last_three_weeks$daily_retail_recreation_2wk_lag <- head(tail(knox_diff$daily_retail_recreation, 21+14),21)



temp = tempfile(fileext = ".xlsx")
dataURL <- "https://www.tn.gov/content/dam/tn/health/documents/cedep/novel-coronavirus/datasets/Public-Dataset-County-New.XLSX"
download.file(dataURL, destfile=temp, mode='wb')

daily <- readxl::read_xlsx(temp, sheet =1, col_types=c("date", "text", rep("numeric",18)))

daily_knox <- subset(daily, COUNTY=="Knox")

daily_focal <- subset(daily, COUNTY %in% c("Knox", "Anderson", "Sevier"))

knox_pop <- max(knox$population)

```

The number of new and active cases should be not be going up if things are well-controlled, and ideally should be going down. The number of active cases is the number of positive cases minus the total of recovered or deceased cases: note it is from those tested and shown to be positive, but there are likely more people with covid who have not been tested. This uses data from https://www.tn.gov/health/cedep/ncov/data/downloadable-datasets.html. Note that the number of active cases in Knox County reported by the state differs from the <a href="https://covid.knoxcountytn.gov/case-count.html#covid_data">county website</a>, sometimes dramatically (on June 16, the county website said 102 active cases, while the state says 178, for example) -- I suspect this is based on the number of recovered cases not being updated as quickly in the state data, but I do not know. Knox County does not seem to offer a download of their data through time, so I am using the state's data. The number of new cases per day seems to align fairly well, but not perfectly, between the state and county data, too.

```{r plotsA, echo=FALSE, message=FALSE, warning=FALSE}


knox_new <- ggplot(daily_knox[!is.na(daily_knox$NEW_CASES),], aes(x=DATE, y=NEW_CASES)) + geom_smooth() + geom_point() + ylab("Number of new cases in Knox each day") + xlab("Date") + ylim(0,NA)
print(knox_new)

knox_active <- ggplot(daily_knox[!is.na(daily_knox$TOTAL_ACTIVE),], aes(x=DATE, y=TOTAL_ACTIVE)) + geom_smooth() + geom_point() + ylab("Number of active cases in Knox each day") + xlab("Date") + ylim(0,NA)
print(knox_active)


```



```{r greenzone, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
# Knox County has published <a href="https://covid.knoxcountytn.gov/case-count.html#covid_data">its guidelines</a>. For it to be green for the number of new cases, it requires "No three-day shifts of 1.5 standard deviations above a rolling mean (based on data from the previous 14 days)." It's not quite clear to me what this means (the average of the three days can't exceed this or **all** or **any** of the three days can't exceed it?);  I'm taking the interpretation that if the three day mean is above this value, there's a problem. They update their stop lights weekly; this looks at each day to see if the average of that day and the two previous days exceeds what seems to be their threshold. Remember that this is just me playing with the data -- they're the experts to decide if cases are growing enough to be worrisome.


GetZone <- function(cases) {
  if(length(cases[!is.na(cases)])<17) {
    return("black")
  }
  old.cases <- head(tail(cases,17),14)
  new.cases <- tail(cases,3)
  max.allowed.green <- mean(old.cases, na.rm=TRUE)+1.5*sd(old.cases, na.rm=TRUE)
  max.allowed.yellow <- mean(old.cases, na.rm=TRUE)+3*sd(old.cases, na.rm=TRUE)
  result <- "red"
  if(mean(new.cases, na.rm=TRUE)<max.allowed.yellow) {
    result <- "yellow"
  }
  if(mean(new.cases, na.rm=TRUE)<max.allowed.green) {
    result <- "green"
  }
  return(result)
}

daily3_knox <- data.frame(date=daily_knox$DATE[-(1:2)], avg=NA, col="darkgray", stringsAsFactors = FALSE)
for(i in sequence(nrow(daily3_knox))) {
  daily3_knox$avg[i] <- mean(daily_knox$NEW_CASES[i:(i+2)])
  daily3_knox$col[i] <- GetZone(head(daily_knox$NEW_CASES,i+2))
}

daily3_knox <- daily3_knox[!is.na(daily3_knox$avg),]
daily3_knox$col <- gsub("yellow", "yellow2", daily3_knox$col)
daily3_knox$col <- gsub("black", "darkgray", daily3_knox$col)

knox_new3 <- ggplot(daily3_knox, aes(x=date, y=avg)) + geom_smooth() + geom_point(shape=21, colour="black", fill=daily3_knox$col) + ylab("Three day average of new cases") + xlab("Date") + ylim(0,NA)
print(knox_new3)

```

A question is whether testing is adequate. The White House has said about 30 tests per 1000 people per month is adequate (this is also what <a href="https://projects.propublica.org/reopening-america/#notes">ProPublica</a> uses); others have argued that around 45 tests per 1000 people per month is better, though with variation depending on infection rate (see <a href="https://www.statnews.com/2020/04/27/coronavirus-many-states-short-of-testing-levels-needed-for-safe-reopening/">here</a>). These are the black lines on the plots below (calculated as tests per day, given Knox County's population of `r knox_pop`).


```{r plotsB, echo=FALSE, message=FALSE, warning=FALSE}


knox_testing <- ggplot(daily_knox[!is.na(daily_knox$NEW_TESTS),], aes(x=DATE, y=NEW_TESTS)) + geom_smooth() + geom_point() + ylab("Number of new tests in Knox each day") + xlab("Date") + ylim(0,NA)
knox_testing <- knox_testing + geom_hline(yintercept=(knox_pop*45/1000)/30, col="black") + geom_hline(yintercept=(knox_pop*30/1000)/30, col="black")
print(knox_testing)


```

Another way to look at testing (or disease spread) is to look at the proportion of positive tests ("positivity rate"): they can go up if a greater proportion of symptomatic people are being tested and/or if the frequency of the disease is increasing. WHO recommends testing should be 10% positive or lower (black line). Here, I'm including two nearby counties, Anderson (home of Oak Ridge) and Sevier (home of Pigeon Forge, Gatlinburg, and Sevierville).


```{r plotsB2, echo=FALSE, message=FALSE, warning=FALSE}

# daily_knox$NEW_PROPORTION_CONFIRMED <- 100*daily_knox$NEW_CONFIRMED/daily_knox$NEW_TESTS
#
# knox_proportion_pos <- ggplot(daily_knox[!is.na(daily_knox$NEW_PROPORTION_CONFIRMED),], aes(x=DATE, y=NEW_PROPORTION_CONFIRMED)) + geom_smooth() + geom_point() + ylab("Percentage of positive tests in Knox each day") + xlab("Date") + ylim(0,NA) + geom_hline(yintercept=10, col="black")
# print(knox_proportion_pos)


daily_focal$NEW_PROPORTION_CONFIRMED <- 100*daily_focal$NEW_CONFIRMED/daily_focal$NEW_TESTS

focal_proportion_pos <- ggplot(daily_focal[!is.na(daily_focal$NEW_PROPORTION_CONFIRMED),], aes(x=DATE, y=NEW_PROPORTION_CONFIRMED, group=COUNTY)) + geom_smooth(aes(colour=COUNTY)) + ylab("Percentage of positive tests in focal counties each day") + xlab("Date") + ylim(0,NA) + geom_hline(yintercept=10, col="black") + scale_colour_viridis_d(end=0.8)
print(focal_proportion_pos)

# par(mfcol=c(1,2))
# plot(knox$date, knox$confirmed, type="l")
# confirmed.ts <- ts(data=knox$confirmed, start=knox$date[1], end=knox$date[length(knox$date)])
# confirmed_plot <- confirmed.ts %>%
#   auto.arima() %>%
#   forecast(h=20) %>%
#   autoplot()
# print(confirmed_plot)

```

Which age groups are being infected is an important question as local schools open up. These are data from Knox county alone.

```{r age, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE}
# covidServer <- get.rds("https://knxhx.richdataservices.com/rds")
# catalog <- getCatalog(covidServer, "kcdh")
# products <- getDataProducts(catalog)
# dataProduct <- getDataProduct(catalog, "us_tn_kchd_age")
# { sink("/dev/null"); ages <- rds.select(dataProduct, autoPage =  TRUE)@records; sink(); }
# ages$Age <- as.character(ages$age_group)
# ages$age_group <- as.numeric(as.character(ages$age_group))
# ages$Age[(ages$age_group%%10==1)] <- paste(ages$age_group[(ages$age_group%%10==1)],"-",ages$age_group[(ages$age_group%%10==1)]+9, sep="")
# ages$Age[ages$age_group==0] <- "0-10"
# ages$Age[ages$age_group==99] <- "100+"
# ages$pct_confirmed <- as.numeric(as.character(ages$pct_confirmed))
#
# label_indices <- which(ages$date_stamp == min(ages$date_stamp) | ages$date_stamp == max(ages$date_stamp))
# labels <- rep("", nrow(ages))
# labels[label_indices] <- ages$Age[label_indices]
# ages$Label <- labels
#
# ageplot <- ggplot(ages, aes(x=date_stamp, y=pct_confirmed, group=Age)) + geom_line(aes(colour=Age)) + ylab("Cumulative percent of cases in each age group") + xlab("Date") + scale_colour_viridis_d(end=0.8) + geom_label_repel(aes(label = Label),na.rm = TRUE) + guides(colour = "none")
# print(ageplot)
```

```{r age2, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE}

temp = tempfile(fileext = ".xlsx")
dataURL <- "https://www.tn.gov/content/dam/tn/health/documents/cedep/novel-coronavirus/datasets/Public-Dataset-Daily-County-Age-Group.XLSX"
download.file(dataURL, destfile=temp, mode='wb')

age_county <- readxl::read_xlsx(temp, sheet =1)
age_county <- subset(age_county, AGE_GROUP != "Pending")

age_county$AGE_GROUP_SIMPLE <- age_county$AGE_GROUP
age_county$AGE_GROUP_SIMPLE <- gsub("71-80 years", "71+ years", age_county$AGE_GROUP_SIMPLE)
age_county$AGE_GROUP_SIMPLE <- gsub("81\\+ years", "71+ years", age_county$AGE_GROUP_SIMPLE)
age_county %<>% group_by(COUNTY, AGE_GROUP_SIMPLE, DATE) %>% mutate(SUM_CASE_COUNT = sum(CASE_COUNT))
age_county <- subset(age_county, AGE_GROUP != "81+ years") #get rid of pruned
age_county <- data.frame(DATE=age_county$DATE, COUNTY=age_county$COUNTY, AGE_GROUP = age_county$AGE_GROUP_SIMPLE, CASE_COUNT=age_county$SUM_CASE_COUNT)

age_county %<>% group_by(COUNTY, AGE_GROUP) %>% mutate(Difference=CASE_COUNT - lag(CASE_COUNT))
age_county %<>% group_by(COUNTY, DATE) %>% mutate(PercentDaily=100*Difference/sum(Difference), PercentCumulative=100*CASE_COUNT/sum(CASE_COUNT))

ageplot_knox_daily <- ggplot(subset(age_county, COUNTY=="Knox"), aes(x=DATE, y=PercentDaily, group=AGE_GROUP)) + geom_smooth(aes(colour=AGE_GROUP), se=FALSE) + ylab("Daily percentage of cases by age group in Knox County (smoothed)") + xlab("Date") + scale_colour_brewer(type="qual", palette="Dark2")
ageplot_knox_cumulative <- ggplot(subset(age_county, COUNTY=="Knox"), aes(x=DATE, y=PercentCumulative, group=AGE_GROUP)) + geom_line(aes(colour=AGE_GROUP)) + ylab("Cumulative percentage of cases by age group in Knox County") + xlab("Date") + scale_colour_brewer(type="qual", palette="Dark2")
#ageplot_knox_both <- ggarrange(ageplot_knox_daily, #ageplot_knox_cumulative, labels=c("Daily", "Cumulative"), ncol=2, nrow=1)
print(ageplot_knox_daily)
print(ageplot_knox_cumulative)

```

Another question is what is happening at UT as campus opens up and testing ramps up. There is some information on active cases available.

```{r utactive, echo=FALSE, message=FALSE, warning=FALSE}
webfiles <- list.files(path="/Users/bomeara/Dropbox/UTKCovid", pattern="*html", full.names =TRUE)
utk.cases <- data.frame()
for(i in seq_along(webfiles)) {
  raw <- paste0(readLines(webfiles[i]),collapse=" ")
  raw <- gsub('\\x3c', '', raw, fixed=TRUE)
  raw <- gsub('\\x3d', '', raw, fixed=TRUE)
  raw <- gsub('\\x3e', '', raw, fixed=TRUE)
  raw <- gsub('/span/tdtd style\"width: \\d+\\.*\\d*%;\"span style\"font-size: 18px;\"', '', raw, fixed=FALSE)
  raw <- gsub('/span/tdtd style\"width: \\d+\\.*\\d*%; text-align: left;\"span style\"font-size: 18px;\"', '', raw, fixed=FALSE)
  students <- as.numeric(gsub("Students", "", stringr::str_extract(raw, "Students\\d+")))
    faculty <- as.numeric(gsub("Faculty", "", stringr::str_extract(raw, "Faculty\\d+")))
    staff <- as.numeric(gsub("Staff", "", stringr::str_extract(raw, "Staff\\d+")))
  actual_time <- anytime::anytime(stringr::str_extract(webfiles[i], "\\d+_\\d+_\\d+_\\d+_\\d+_\\d+"))
  result <- data.frame(date=rep(actual_time, 3), count=c(students, faculty, staff), group=c("students", "faculty", "staff"))
  if(i==1) {
    utk.cases <- result
  } else {
    utk.cases <- rbind(utk.cases, result)
  }
}
utk.cases$group <- as.factor(utk.cases$group)
utk_plot <- ggplot(utk.cases, aes(x=date, y=count, group=group)) + geom_line(aes(colour=group)) + ylab("Number of active cases at UTK") + xlab("Date") + ylim(0,NA) + scale_colour_viridis_d(end=0.8)
print(utk_plot)
```

I've been curious about how active people have been -- are they still going out, etc. The webcams at the bottom of the page are a glimpse of that, but Google has also been tracking activity data. Here are smoothed plots of activity over time, as a percentage of activity pre-COVID19 (the raw data are much more variable).

```{r plotsC, echo=FALSE, message=FALSE, warning=FALSE}

knox_activity <- reshape2::melt(knox[,c("date", colnames(knox)[grepl("baseline", colnames(knox))])],id.var='date')
knox_activity <- knox_activity[!grepl("transit", knox_activity$variable),]
knox_activity$variable <- gsub("_percent_change_from_baseline", "", knox_activity$variable )
knox_activity <- knox_activity[!is.na(knox_activity$value),]
g <- ggplot(knox_activity, aes(x=date, y=value, col=variable)) + geom_smooth() + ylab("Activity in Knox County over time as percentage of baseline activity\nData from Google")
g <- g + geom_hline(yintercept=0, col="black")
print(g)

# p <- ggplot(knox_diff, aes(x=date, y=daily_confirmed)) + geom_smooth(span=14/nrow(knox_diff)) + geom_point()
# print(p)

```

<hr />

<h2>Hospitalization</h2>


```{r hospitalcapacitydata, echo=FALSE, message=FALSE, warning=FALSE}

covidServer <- get.rds("https://knxhx.richdataservices.com/rds")
catalog <- getCatalog(covidServer, "kchd")
products <- getDataProducts(catalog)
dataProduct <- getDataProduct(catalog, "us_tn_kchd_capacity")
{ sink("/dev/null"); hospital_resources <- rds.select(dataProduct, autoPage =  TRUE)@records; sink(); }
hospital_resources$label = NA
hospital_resources$label[hospital_resources$resource_type==0] <- "All beds"
hospital_resources$label[hospital_resources$resource_type==1] <- "ICU beds"
hospital_resources$label[hospital_resources$resource_type==2] <- "Ventilators"
hospital_resources$cnt_available <- as.numeric(as.character(hospital_resources$cnt_available))
hospital_resources$cnt_capacity <- as.numeric(as.character(hospital_resources$cnt_capacity))
hospital_resources$pct_used <- as.numeric(as.character(hospital_resources$pct_used))
hospital_resources$pct_available <- as.numeric(as.character(hospital_resources$pct_available))


# hospitalfiles <- list.files(path="/Users/bomeara/Dropbox/KnoxCovid", pattern="*bed*", full.names =TRUE)
# capacity.df <- data.frame()
# previoushospitaldata <- data.frame()
# current.capacity.df <- data.frame()
# for (i in seq_along(hospitalfiles)) {
#   actual_time <- anytime::anytime(stringr::str_extract(hospitalfiles[i], "\\d+_\\d+_\\d+_\\d+_\\d+_\\d+"))
#   hospitaldata <- read.csv(hospitalfiles[i], stringsAsFactors=FALSE)
#   hospitaldata$Current.Utilization <- as.numeric(gsub('%', '', hospitaldata$Current.Utilization))
#   hospitaldata$Resource <- hospitaldata$East.Region.Hospitals
#
#   if(i==1) {
#     previoushospitaldata <- hospitaldata
#     hospitaldata$Date <- actual_time
#     capacity.df <- hospitaldata
#   } else {
#     if(all(dim(hospitaldata)==dim(previoushospitaldata))) {
#       if(any(hospitaldata!=previoushospitaldata)) {
#         previoushospitaldata <- hospitaldata
#         hospitaldata$Date <- actual_time
#         capacity.df <- rbind(capacity.df, hospitaldata)
#       }
#     }
#   }
#   current.capacity.df <- hospitaldata
#   rownames(current.capacity.df) <- current.capacity.df$Resource
# }
```

Currently, regional hospitals have `r tail(subset(hospital_resources, label=="ICU beds")$cnt_available,1)` ICU beds available of `r tail(subset(hospital_resources, label=="ICU beds")$cnt_capacity,1)` total, and `r tail(subset(hospital_resources, label=="Ventilators")$cnt_available,1)` available ventilators out of `r tail(subset(hospital_resources, label=="Ventilators")$cnt_capacity,1)` total. When a line hits 100%, the local hospitals are theoretically full for that resource (for all patients, not just covid patients), though there is surge capacity on top of this. Note that these data are not updated frequently, so current conditions maybe be much better or worse than these plots show. Data from <a href="https://knxhx.richdataservices.com/">https://knxhx.richdataservices.com/</a>.


```{r hospitalcapacityplot, echo=FALSE, message=FALSE, warning=FALSE}
try(hosp_plot <- ggplot(hospital_resources, aes(x=date_stamp, y=pct_used, group=label)) + geom_line(aes(colour=label)) + ylab("Percent Utilization in East Tennessee Region") + xlab("Date") + ylim(0,100) + scale_colour_viridis_d(end=0.8))
try(print(hosp_plot))

```

Trends in hospitalization of covid patients over time

```{r plotsD, echo=FALSE, message=FALSE, warning=FALSE}


knox_new_hospitalization <- ggplot(daily_knox[!is.na(daily_knox$NEW_HOSPITALIZED),], aes(x=DATE, y=NEW_HOSPITALIZED)) + geom_smooth() + geom_point() + ylab("Number of new covid hospitalizations in Knox each day") + xlab("Date") + ylim(0,NA)
print(knox_new_hospitalization)

tn_daily_aggregate <- daily %>% group_by(DATE) %>% summarise(new_hosp = sum(NEW_HOSPITALIZED))


tn_new_hospitalization <- ggplot(tn_daily_aggregate[!is.na(tn_daily_aggregate$new_hosp),], aes(x=DATE, y=new_hosp)) + geom_smooth() + geom_point() + ylab("Number of new covid hospitalizations in TN each day") + xlab("Date") + ylim(0,NA)
print(tn_new_hospitalization)

# all_confirmed <- data.frame(date=c(us_aggregate$date, tn_aggregate$date, knox$date), percentconfirmed=c(us_aggregate$percentconfirmed, tn_aggregate$percentconfirmed, knox$percentconfirmed), region=c(rep("US", nrow(us_aggregate)),rep("TN", nrow(tn_aggregate)), rep("Knox", nrow(knox))))
# con <- ggplot(all_confirmed, aes(x=date, y=percentconfirmed, color=region)) + geom_smooth() + geom_point() + ylab("Percent of population with confirmed tests")
# print(con)
#
# three_weeks_ago <- tail(sort(unique(all_confirmed$date)),21)[1]
# all_confirmed_3 <- all_confirmed[all_confirmed$date>=three_weeks_ago,]
#
# con3 <- ggplot(all_confirmed_3, aes(x=date, y=percentconfirmed, color=region)) + geom_smooth() + geom_point() + ylab("Percent of population with confirmed tests")
# print(con3)
#
# diff_confirmed <-  data.frame(date=c(us_diff$date, tn_diff$date, knox_diff$date), daily_percent_confirmed=c(us_diff$daily_percent_confirmed, tn_diff$daily_percent_confirmed, knox_diff$daily_percent_confirmed), region=c(rep("US", nrow(us_diff)),rep("TN", nrow(tn_diff)), rep("Knox", nrow(knox_diff))))
# diffplot <- ggplot(diff_confirmed, aes(x=date, y=daily_percent_confirmed, color=region)) + geom_smooth(span=14/nrow(knox_diff)) + geom_point() + ylab("Percent of population new confirmed tests daily")
# print(diffplot)
#
#
# diff_confirmed_3 <- diff_confirmed[diff_confirmed$date>=three_weeks_ago,]
# diffplot3 <- ggplot(diff_confirmed_3, aes(x=date, y=daily_percent_confirmed, color=region)) + geom_smooth() + geom_point() + ylab("Percent of population new confirmed tests daily")
# print(diffplot3)

```

<hr />

<h2>Local webcams</h2>

Downtown Gatlinburg <a href="http://www.smokyfrontier.com/">webcam</a>, a tourist town near us

<iframe src="http://www.smokyfrontier.com/"  width=600 height=600 scrolling="no"></iframe>



<a href="https://www.air-resource.net/grsmnfgap/">Newfound Gap in the Smokies</a>

Note that at night there are typically no lights here, so it will be a black screen. During the day you can see a parking lot in the mountains.

<iframe src="https://www.air-resource.net/grsmnfgap/" width=600 height=500 scrolling="no"></iframe>
